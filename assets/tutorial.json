[
    {
        "headers": ["Introduction", "Neural Networks"],
        "text": [
            "Have you ever wondered how A.I. worked? Why does it work and how is it able to achieve such complicated tasks spanning from translating languages to object and face detection? A.I. and machine learning are two very complicated subjects and it is very hard to visualise them. I am a visual learner myself and I was not able to find many resources that let you visualise how A.I. works, so I have decided to create one myself. \n\nThis application is an interface that allows you to create your own \"brain\" that will learn to separate dogs from cats. This tutorial will prepare everyone, beginner or advanced users, and will make machine learning an easier concept to grasp. \n\nThe principle of an artificial neural network is to mimic the process of biological neural networks within our brains in order to inherit the learning capabilities that come to us naturally. In the case of image recognition, we know what the expected output is, and we can feed this information in. Humans learn what the world around us looks like since they are born, and it takes us years of practice every day to recognise different objects, animals or other humans. A human can instantly spot even the slightest differences between different objects. If we have two chairs, and they are different colours, we can still recognise them as chairs because we have learnt the specific patterns of a chair. Although we do this subconsciously, computers lack this ability because their \"brains\" are different to ours.",
            "\"Enough, let me show how it works!\" For the sake of simplicity, suppose we have a brain made out of a single neuron. This neuron will receive some information (input), it will process it, and spit out some result (output). \n\n <image> \n\nBoth the inputs and outputs will be numbers; however, it depends on the programmers how they interpret it. Our application will take images of dogs and cats as inputs, but they are merely just some numbers. An image is stored as a grid of pixels, and each pixel is represented by the binary representation of its colour.\n\nThe processing bit is actually surprisingly easy. Each neuron has a weight attached to it and the output is calculated by multiplying the input with the weight. Easy, right? A layer is made out of multiple neurons and a neural network is made out of multiple layers. It usually becomes so complex it becomes meaningless to a human.\n\nIn our example we will use two types of layers, fully connected and convolutional layers. Click the right arrow to go to the next page!"
        ]
    },
    {
        "headers": ["Fully-connected layers", "Convolutional layers"],
        "text": [
            "This type of layer is used in 99% of each neural network (this is a made-up figure, but you get the point). Suppose we have this network below. Each circle represents a neuron. \n\n <image> \n\nThe input layer takes in two numerical values, x and y. Each output is then sent as an input to each neuron in the hidden layer. When there are multiple inputs, we multiply the sum by the weight. The output neuron receives the three output numbers and in the end it will give out a value. This value can be interpreted differently depending on the activation function of the network. Do not worry, we will talk about activation functions later. \n\nYou will see when editing a fully connected layer that you will be able to edit the \"dropout size\". We don't want the network to learn too much from the training data, and therefore those outputs will need to be regularised. This will randomly set input units to 0 with a frequency of \"dropout size\" at each step during training time, which helps prevent learning too much from the data. From now on, we will use the term \"overfitting\".",
            "Convolutional layers have the same idea behind, numbers moving forward the network, however, the weights are two dimensional and they are called filters instead. They are suited to images because images are stored in a 2D grid. Instead of multiplying the inputs with a single number, we multiply each number in the grid with its corresponding number in the filter. \n\nThe neural network that we will be using is called a CNN (Convolutional Neural Network) because it contains both types of layers. \n\nYou will see when editing a convolutional layer that you will be able to edit \"the pool size\". This has a similar effect as the \"dropout size\". It will split the output grid into squares of the pool size and it will create a new grid using the maximum numbers. Below, there is an example of this process called \"pooling\" with a pool size of 2. \n\n <image> \n\nWhy does this work? Because those smaller numbers are features in each particular image of a dog for example. However we could have another image of a dog but these features may be different and the network might incorrectly assume it is a cat instead."
        ]
    },
    {
        "headers": ["Finishing touches", "Training and testing the network"],
        "text": [
            "The network will not be complete without some variables. You will be able to edit two variables, optimiser and learning rate. \n\nWhen training data, we need to find a way to adjust each weight in order to make the network more accurate. At first, the network would guess randomly if it is a dog or a cat and based on its results, it will adjust the corresponding weights. Now, how do we do this? For most convolutional neural networks, there are 3 main functions that we call optimisers: RMSprop, Adam and SGD (stochastic gradient descent). \n\n <image> \n\nn - the number of samples (training data) \n\ny - the output of the network (true - actual output, pred - prediction) \n\nThis function will calculate the error of the network and this value will be passed back to the input neurons in order to work out the error of each weight. It requires some maths which you don't need to worry about, but you can choose between the 3 functions to see how it affects the network. Below there are some explanations in simple words. \n\nSGD - it tests a sample and if the error is negative, the weight will decrease; if the error is positive, the weight will increase \n\nRMSprop - it would change the learning rate according to the change in the weight (we will discuss the learning rate in the next paragraph) \n\nAdam - this one is a mix of the SGD and RMSprop \n\nWhat is the learning rate? This is the most important hyperparameter in a neural network and it changes by how much the weights should be changed during training. You will be able to edit the learning rate only when using SGD since both RMSprop and Adam would change the learning rate when training. A learning rate that is too large can cause the model to learn too much from the data, whereas a learning rate that is too small can cause the process to get stuck. \n\nEarlier I was discussing activation functions, what are they? They are used to map the output of each neuron to a specific range. There are two functions we will be using, but there are plenty more which could be used. ReLU is a function that maps every negative value to 0 and does not affect positive values. This is particularly useful in convolutional layers because we cannot have negative pixel values. We also use sigmoid which is more complex. It maps every value to a range between 0 and 1. As it is used in the output layer, we know the range between 0 and 0.5 represents a cat and 0.5 to 1 represents a dog. \n\n <image>",
            "The application comes with a dataset of 25000 images of dogs and cats and it is split in the following way: \n\nTraining data - 10000 images of dogs and 10000 images of cats \n\nValidation data - 2000 images of dogs and 2000 images of cats \n\nTesting data - 500 images of both dogs and cats \n\nThe training and validation data come up with a label that will say if it's either a dog or a cat. The network would look at each sample in the training data and edit the weights accordingly, and then it would look at each sample in the validation data just to check how well it does on untested data. \n\nIf the accuracy on the validation dataset is not similar to the training dataset, that means the network is overfitting and you might need to edit the network. \n\nThe testing dataset is a smaller dataset that is used to evaluate the network on the data that it has never seen before. If you click \"ADD DATA\" you will be able to add your own image of a dog or a cat and test the network. Fingers crossed! \n\nWhen you click \"TRAIN\" you will notice you will be asked to write how many epochs you want to train the network for. What is an epoch? An epoch is a full iteration over samples. The number of epochs is how many times the algorithm is going to run. The more the epochs, the more accurate the network will be. \n\nIf you want to see how accurate your network is, you can click the button \"Click here to view how accuracy changes over time\" and you will see a graph that goes up, hopefully. You can also check how loss (or the error) changes over time, this is the value that needs to be minimised."
        ]
    },
    {
        "headers": ["Editing layers", "Loading and saving the network"],
        "text": [
            "The application has a limit of 4 convolutional layers and 4 fully-connected layers (including the input convolutional layer and the output fully-connected layer). You cannot delete the input and output layer and the first hidden convolutional layer. You can edit the following: \n\nNumbers of filters/neurons \n\nThe more the neurons, the more resources you need to train the network, but it may get more accurate; donâ€™t exaggerate :) \n\nKernel size [C] \n\nThis is how big the filters are, 3x3, 5x5 and 7x7 are the only options \n\nStride and padding [C] \n\nThe stride will decide how many cells you want to skip when multiplying the input by the filter; choose the number wisely because you don't want to lose too much detail. Most of the time the pixels on the sides are not that important. In order to tell the neural network that those pixels should be counted less, pixels of value zero are added to sides. This is called padding and you will have a choice of \"valid\" or \"same\". \"Valid\" means no padding and \"same\" means zeroes will be added. \n\n [C] - convolutional layer",
            "If you want to come back to your network, you can save it by clicking the button \"SAVE\". When you come back, you can press \"Load Neural Network\" on the main menu and select the network you want to work on. You can train the network as many times as you want and you will be able to see how it performed in the past since the accuracy and loss values will be saved."
        ]
    },
    {
        "headers": ["Dictionary", "Create a network"],
        "text": [
            "Studying machine learning is a tedious process and you will not be able to remember every single term at once. You can click the info button next to a complex term and it will explain to you what it does, or alternatively you can press \"What do these complicated words mean?\" on the main menu and you can search for your term. It's ordered alphabetically.",
            "I hope this tutorial was helpful to you, you can come back to it any time and if you want to create a network without having to go through the tutorial again, you can press \"Create New Network\" on the main menu. Good luck! :)"
        ]
    }
]